import json
import time
import logging
import google.api_core.exceptions
from modules.bigquery import BigQuery
from google.cloud import secretmanager
from modules.fk_ids import FakeDataPerson
from modules.fk_address import FakeDataAddress
from modules.transformation import hide_data, add_columns, split_data


logging.basicConfig(
    format=("%(asctime)s | %(levelname)s | File_name ~> %(module)s.py "
            "| Function ~> %(funcName)s | Line ~~> %(lineno)d  ~~>  %(message)s"),
    level=logging.INFO
)


def check_authorization(data_dict: dict) -> bool:
    """
    Retrieves the secret key from Google Cloud Secret Manager.

    Args:
        data_dict (dict): A dictionary containing the project ID and secret ID.

    Returns:
        bool: True if the secret key is successfully retrieved, False otherwise.

    Raises:
        Exception: If access to the secret key is denied.

    """

    client      = secretmanager.SecretManagerServiceClient()
    secret_url  = {
        "name": f"projects/{data_dict['project_id']}/secrets/{data_dict['secret_id']}/versions/latest"
    }

    try:
        result = client.access_secret_version(secret_url)
        return json.loads(result.payload.data.decode("UTF-8"))

    except google.api_core.exceptions.GoogleAPICallError as e:
        logging.error(f"Access to secret key denied")
        raise f"Access denied! --> {e}"


def generate_fake_data() -> dict:
    """
    Generates fake customer data including customers, cards, and addresses.

    Returns:
        dict: A dictionary containing:
            - "customers": Fake customer data generated by FakeDataPerson.
            - "cards": Fake card data generated by FakeDataPerson.
            - "address": A randomly generated address from FakeDataAddress.
    """

    fk_person   = FakeDataPerson()
    fk_address  = FakeDataAddress()

    return \
        {
            "customers" : fk_person.dict_customers(),
            "cards"     : fk_person.dict_card(),
            "address"   : fk_address.get_random_address()
        }


def main(request: dict) -> dict:
    """
    Processes a request to generate, transform, and insert fake customer data into BigQuery tables.

    Args:
        request (dict): The request payload containing configuration parameters. If not a dict, attempts to parse JSON from the request object.

    Returns:
        list: A list of generated fake data records after processing.

    Raises:
        AuthorizationError: If the request fails authorization.
        KeyError: If required keys ('number_customers', 'project_id', 'table_id', 'dataset_id') are missing in the request.
        Exception: For errors during data generation, transformation, or insertion into BigQuery.

    Workflow:
        1. Validates and parses the request.
        2. Checks authorization.
        3. Generates fake data records.
        4. Hides sensitive data.
        5. Adds additional columns to the data.
        6. Splits data into structured components (customers, cards, address).
        7. Inserts structured data into specified BigQuery tables.
    """

    if type(request) != dict:
        dt_request = request.get_json()
    else:
        dt_request = request

    logging.info("Validating access, please wait...")
    credentials = check_authorization(dt_request)
    logging.info("Access granted, proceeding with data generation...")

    logging.info("Generating fake data...")
    list_fake_data = [generate_fake_data() for _ in range(credentials['number_customers'])]

    logging.info("Hiding sensitive data...")
    list_fake_data = hide_data(list_fake_data)


    logging.info("Adding columns to the data...")
    list_fake_data = add_columns(list_fake_data)
    logging.info("Columns added successfully.")

    logging.info("Splitting data into customers, cards, and address...")
    structured_data = split_data(list_fake_data)
    logging.info("Data split successfully.")

    logging.info("Data structure ready for insertion into BigQuery.")
    logging.info("Inserting data into BigQuery...")
    bq_client = BigQuery(project=credentials['project_id'])
    for table in credentials['table_id']:
        logging.info(f"Inserting data into {credentials['dataset_id']}.{table}...")
        bq_client.batch_load_from_memory(
            data    = structured_data[table],
            dataset = credentials['dataset_id'],
            table   = table
        )
        logging.info(f"Data inserted successfully into {credentials['dataset_id']}.{table}.")

    logging.info("All data inserted successfully into BigQuery tables.")

    return \
        {
            "status": 200,
            "message": f"Whole process completed successfully! {credentials['number_customers'] * 3} records processed."
        },



if __name__ == "__main__":
    # request_dict = \
    #     {
    #         "number_customers"    : 1_000,
    #         'project_id'    : 'mts-default-portofolio',
    #         'dataset_id'    : 'ls_customers',
    #         'table_id'      : ['tb_customers', 'tb_cards', 'tb_address'],
    #         'secret_id'     : 'bq_customers_access_authorization'
    #     }


    main({
            "project_id": "mts-default-portofolio",
            "secret_id": "bq_customers_access_authorization"
        })

